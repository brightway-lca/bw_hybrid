{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Investigation of Hybrid Life-Cycle Assessment Matrix Calculations\n",
    "\n",
    "This notebook is available online at this Zenodo Record: [`doi:10.5281/zenodo.14786979`](https://doi.org/10.5281/zenodo.14786979)\n",
    "\n",
    "Note that this investigation was originally run in January 2025 run using a virutal environment with the following packages:\n",
    "\n",
    "```\n",
    "numpy==2.2.1\n",
    "scipy==1.15.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scientific computing\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(seed=42)\n",
    "import pandas as pd\n",
    "# data storage\n",
    "import gzip\n",
    "import pickle\n",
    "# system libraries\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Compressed Data from `pylcaio` Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "path = '/Users/michaelweinold/data/HLCA/hybrid_system.pickle'\n",
    "with gzip.open(path, 'rb') as pickle_file:\n",
    "    picklefile = pickle.load(file=pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Hybrid Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the definition of the matrices in the output of the [`pylcaio` package](https://github.com/MaximeAgez/pylcaio/tree/master), see [this section of the source code](https://github.com/MaximeAgez/pylcaio/blob/505898a39144ebc53c109e485644e3ea055ae0ae/src/pylcaio.py#L46\n",
    ").\n",
    "\n",
    "The matrices are defined as follows:\n",
    "\n",
    "| Symbol | Dimension | Units | Description |\n",
    "| ------ | --------- | ----- | ----------- |\n",
    "| $\\mathbf{A}_P$ | $M \\times M$ | [kg] (\"physical\") | technosphere matrix |\n",
    "| $\\mathbf{A}_S$ | $N \\times N$ | [\\$] (\"monetary\") | technical coefficient matrix |\n",
    "| $\\mathbf{C}_U$ | $N \\times M$ | [\\$/kg] |  upstream cut-off matrix |\n",
    "| $\\mathbf{B}_P$ | $R \\times M$ | [CO₂/kg] (\"environmental flow\") | biosphere matrix |\n",
    "| $\\mathbf{B}_S$ | $P \\times N$ | [CO₂/\\$] (\"environmental flow\") | environmental satellite matrix |\n",
    "| $\\mathbf{Q}_P$ | $1 \\times R$ | [°warming/CO₂] | characterization matrix process system |\n",
    "| $\\mathbf{Q}_S$ | $1 \\times P$ | [°warming/CO₂] | characterization matrix sectoral system |\n",
    "\n",
    "Note that for simplicity, here we assume that we have only a single environmental burden (global warming potential). Therefore the dimension of $\\mathbf{Q}=1 \\times ...$.\n",
    "\n",
    "The hybrid matrices are then build such that:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{A}_H &= \\begin{bmatrix}\n",
    "\\mathbf{A}_P & \\mathbf{0} \\\\\n",
    "\\mathbf{C}_U & \\mathbf{A}_S\n",
    "\\end{bmatrix} \\\\\n",
    "\\mathbf{A}_H &= [(M+N) \\times (M+N)]\n",
    "\\end{align}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{B}_H &= \\begin{bmatrix}\n",
    "\\mathbf{B}_P & 0 \\\\\n",
    "0 & \\mathbf{B}_S\n",
    "\\end{bmatrix} \\\\\n",
    "\\mathbf{B}_H &= [(R+P) \\times (M+N)]\n",
    "\\end{align}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{Q}_H &= \\begin{bmatrix}\n",
    "\\mathbf{Q}_P & \\mathbf{Q}_S\n",
    "\\end{bmatrix} \\\\\n",
    "\\mathbf{Q}_H &= [1 \\times (R+P)]\n",
    "\\end{align}\n",
    "\n",
    "Which gives the following equation:\n",
    "\n",
    "\\begin{align}\n",
    "e &= \\mathbf{Q}_H \\cdot \\mathbf{B}_H \\cdot (\\mathbf{A}_H)^{-1} \\cdot \\vec{f} \\\\\n",
    "[1 \\times 1] &= [1 \\times (R+P)] \\cdot [(R+P) \\times (M+N)] \\cdot [(M+N) \\times 1]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_P = picklefile['A_ff'].todense().A\n",
    "A_S = picklefile['A_io'].todense().A\n",
    "C_U = picklefile['A_io_f'].todense().A\n",
    "A_H = np.block(\n",
    "    [\n",
    "        [np.eye(A_P.shape[0]) - A_P, np.zeros((A_P.shape[0], A_S.shape[0]))],\n",
    "        [C_U, np.eye(A_S.shape[0]) - A_S]\n",
    "    ]\n",
    ")\n",
    "\n",
    "B_S = picklefile['F_io'].todense().A\n",
    "B_P = picklefile['F_f'].todense().A\n",
    "B_H = np.block(\n",
    "    [\n",
    "        [B_P, np.zeros((B_P.shape[0], B_S.shape[1]))],\n",
    "        [np.zeros((B_S.shape[0], B_P.shape[1])), B_S]\n",
    "    ]\n",
    ")\n",
    "\n",
    "Q_P_climate = picklefile['C_f'].todense().A[0,:]\n",
    "Q_S_climate = picklefile['C_io'].todense().A[0,:]\n",
    "Q_H_climate = np.atleast_2d(np.concatenate((Q_P_climate, Q_S_climate), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005447512287780848"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "density_A_P = np.count_nonzero(A_P) / A_P.size\n",
    "density_A_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3530680862140775"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "density_A_S = np.count_nonzero(A_S) / A_S.size\n",
    "density_A_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.044552485176151575"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "density_A_H = np.count_nonzero(A_H) / A_H.size\n",
    "density_A_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_demand_vector(\n",
    "    number_of_sectors: int,\n",
    "    sector_index: int,\n",
    "    demand_amount: float\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates a final demand vector with a given demand amount for a given sector and 0 for all other sectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    number_of_sectors : int\n",
    "        Number of sectors in the process database (number of rows or columns in the technosphere matrix).\n",
    "    sector_index : int\n",
    "        Index of the sector for which the final demand vector should be generated.\n",
    "    demand_amount : float\n",
    "        Demand amount for the given sector.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Final demand vector with a given demand amount for a given sector and 0 for all other sectors.\n",
    "    \"\"\"\n",
    "    f_vector = np.zeros(number_of_sectors)\n",
    "    f_vector[sector_index] = demand_amount\n",
    "    return f_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_P = generate_final_demand_vector(\n",
    "    number_of_sectors=A_P.shape[0],\n",
    "    sector_index=0,\n",
    "    demand_amount=1.0\n",
    ")\n",
    "f_H = generate_final_demand_vector(\n",
    "    number_of_sectors=A_H.shape[0],\n",
    "    sector_index=1111,\n",
    "    demand_amount=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(21255, 21255))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 34s, sys: 8.38 s, total: 4min 43s\n",
      "Wall time: 2min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.02459975e-13,  9.44899116e-15,  1.06404106e-14, ...,\n",
       "       -2.62170889e-07, -2.77594759e-07,  0.00000000e+00], shape=(31055,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "np.linalg.solve(A_H, f_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA_P\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/bw_hybrid/.venv/lib/python3.10/site-packages/numpy/linalg/_linalg.py:609\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    606\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call\u001b[38;5;241m=\u001b[39m_raise_linalgerror_singular, invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    608\u001b[0m               over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 609\u001b[0m     ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/github/bw_hybrid/.venv/lib/python3.10/site-packages/numpy/linalg/_linalg.py:104\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "np.linalg.inv(A_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim(A_P)=(21255, 21255)\n",
      "dim(A_S)=(9800, 9800)\n",
      "dim(C_U)=(9800, 21255)\n",
      "dim(A_H)=(31055, 31055)\n",
      "dim(B_P)=(4709, 21255)\n",
      "dim(B_S)=(716, 9800)\n",
      "dim(B_H)=(5425, 31055)\n",
      "dim(Q_P_climate)=(4709,)\n",
      "dim(Q_S_climate)=(716,)\n",
      "dim(Q_H_climate)=(1, 5425)\n"
     ]
    }
   ],
   "source": [
    "print(f'dim(A_P)={A_P.shape}')\n",
    "print(f'dim(A_S)={A_S.shape}')\n",
    "print(f'dim(C_U)={C_U.shape}')\n",
    "print(f'dim(A_H)={A_H.shape}')\n",
    "print(f'dim(B_P)={B_P.shape}')\n",
    "print(f'dim(B_S)={B_S.shape}')\n",
    "print(f'dim(B_H)={B_H.shape}')\n",
    "print(f'dim(Q_P_climate)={Q_P_climate.shape}')\n",
    "print(f'dim(Q_S_climate)={Q_S_climate.shape}')\n",
    "print(f'dim(Q_H_climate)={Q_H_climate.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Random Sample of Ecoinvent Processes\n",
    "\n",
    "Every Ecoinvent process has an industry classification code according to the International Standard Industrial Classification of All Economic Activities (ISIC). We use the highest-level classification structure of the 21 (A-U) ISIC \"sections\" to group Ecoinvent processes (see [\"Classification Structure\"](https://unstats.un.org/unsd/classifications/Family/Detail/27))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_isic_letters_and_numbers = {\n",
    "    'A': ['01', '02', '03'],\n",
    "    'B': ['05', '06', '07', '08', '09'],\n",
    "    'C': [\n",
    "        '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', \n",
    "        '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', \n",
    "        '31', '32', '33'\n",
    "    ],\n",
    "    'D': ['35'],\n",
    "    'E': ['36', '37', '38', '39'],\n",
    "    'F': ['41', '42', '43'],\n",
    "    'G': ['45', '46', '47'],\n",
    "    'H': ['49', '50', '51', '52', '53'],\n",
    "    'I': ['55', '56'],\n",
    "    'J': ['58', '59', '60', '61', '62', '63'],\n",
    "    'K': ['64', '65', '66'],\n",
    "    'L': ['68'],\n",
    "    'M': ['69', '70', '71', '72', '73', '74', '75'],\n",
    "    'N': ['77', '78', '79', '80', '81', '82'],\n",
    "    'O': ['84'],\n",
    "    'P': ['85'],\n",
    "    'Q': ['86', '87', '88'],\n",
    "    'R': ['90', '91', '92', '93'],\n",
    "    'S': ['94', '95', '96'],\n",
    "    'T': ['97', '98'],\n",
    "    'U': ['99']\n",
    "}\n",
    "list_process_metadata_isic = [i for i in picklefile['PRO_f']['ISIC'].values()]\n",
    "list_process_metadata_isic_numbers = [str(string)[:2] for string in list_process_metadata_isic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_process_indices_from_ecoinvent_per_isic_letter(\n",
    "    dict_isic_letters_and_numbers: dict,\n",
    "    list_process_metadata_isic_numbers: list,\n",
    "    number_of_indices_per_isic_letter: int,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Gets a random sample of process indices from the ecoinvent database for each ISIC letter (=sections).\n",
    "\n",
    "    If the number of processes for a given ISIC letter is less than the number of indices to be sampled,\n",
    "    the function will sample all available processes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dict_isic_letters_and_numbers : dict\n",
    "        Dictionary with ISIC letters (=sections) as keys and lists of ISIC numbers (=divisions) as values.\n",
    "        For example: {'A': ['01', '02', '03'], 'B': ['05', '06', '07', '08', '09'], ...}\n",
    "    list_process_metadata_isic_numbers : list\n",
    "        List of ISIC numbers for each process in the ecoinvent database.\n",
    "        For example: ['01', '01', '02', '02', '02', '03', ...]\n",
    "    number_of_indices_per_isic_letter : int\n",
    "        Number of indices to be sampled for each ISIC letter.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with ISIC letters as keys and lists of sampled process indices as values.\n",
    "        For example: {'A': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'B': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19], ...}\n",
    "    \"\"\"\n",
    "    \n",
    "    dict_isic_letters_and_indices = {}\n",
    "\n",
    "    for isic_letter in dict_isic_letters_and_numbers.keys():\n",
    "        list_of_process_indices = []\n",
    "        for isic_number in dict_isic_letters_and_numbers[isic_letter]:\n",
    "            list_of_process_indices += [index for index, element in enumerate(list_process_metadata_isic_numbers) if element == isic_number]\n",
    "        dict_isic_letters_and_indices[isic_letter] = list_of_process_indices\n",
    "\n",
    "    dict_return = {}\n",
    "\n",
    "    for isic_letter, isic_numbers in dict_isic_letters_and_indices.items():\n",
    "        sample_size = number_of_indices_per_isic_letter\n",
    "        if dict_isic_letters_and_indices[isic_letter] == []:\n",
    "            continue\n",
    "        if len(isic_numbers) < number_of_indices_per_isic_letter:\n",
    "            sample_size = len(isic_numbers)\n",
    "        dict_return[isic_letter] = rng.choice(\n",
    "            a=dict_isic_letters_and_indices[isic_letter],\n",
    "            size=sample_size,\n",
    "            replace=False\n",
    "        ).tolist()\n",
    "        \n",
    "    return dict_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': [234, 2109, 243, 1785, 1197, 1181, 1905, 257, 550, 2343],\n",
       " 'B': [3277, 3014, 2990, 3182, 3309, 2860, 3045, 3080, 3115, 3378],\n",
       " 'C': [8679, 9109, 5505, 6773, 6089, 4670, 8162, 10126, 10705, 3942],\n",
       " 'D': [15306, 12787, 14297, 12402, 14016, 14288, 12586, 15029, 11624, 15100],\n",
       " 'E': [18157, 18666, 16330, 18035, 19078, 17884, 17140, 16076, 17629, 16727],\n",
       " 'F': [19942, 19578, 19319, 19498, 19533, 19442, 19900, 20083, 20053, 20059],\n",
       " 'G': [20249, 20263, 20256, 20243, 20255, 20245, 20258, 20254, 20271, 20274],\n",
       " 'H': [20471, 20614, 20446, 20831, 20432, 20720, 20588, 20522, 20397, 20293],\n",
       " 'I': [20851, 20846, 20853, 20850, 20844, 20843, 20849, 20852, 20847, 20848],\n",
       " 'J': [20856, 20868, 20870, 20871, 20854, 20864, 20862, 20867, 20860, 20861],\n",
       " 'M': [20875, 20874, 20876, 20877, 20873, 20872],\n",
       " 'N': [20905, 20962, 20980, 20914, 20968, 20925, 20949, 20906, 20958, 20928],\n",
       " 'S': [20989, 20990, 20986, 20988, 20987]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_sample_process_indices = get_sample_process_indices_from_ecoinvent_per_isic_letter(\n",
    "    dict_isic_letters_and_numbers=dict_isic_letters_and_numbers,\n",
    "    list_process_metadata_isic_numbers=list_process_metadata_isic_numbers,\n",
    "    number_of_indices_per_isic_letter=10\n",
    ")\n",
    "dict_sample_process_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations with Hybrid LCA Matrix\n",
    "\n",
    "The below code simply implements the governing equation of hybrid life-cycle assessment:\n",
    "\n",
    "\\begin{align}\n",
    "e &= \\mathbf{Q}_H \\cdot \\mathbf{B}_H \\cdot (\\mathbf{A}_H)^{-1} \\cdot \\vec{f} \\\\\n",
    "[1 \\times 1] &= [1 \\times (R+P)] \\cdot [(R+P) \\times (M+N)] \\cdot [(M+N) \\times 1]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_demand_vector(\n",
    "    number_of_sectors: int,\n",
    "    sector_index: int,\n",
    "    demand_amount: float\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates a final demand vector with a given demand amount for a given sector and 0 for all other sectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    number_of_sectors : int\n",
    "        Number of sectors in the process database (number of rows or columns in the technosphere matrix).\n",
    "    sector_index : int\n",
    "        Index of the sector for which the final demand vector should be generated.\n",
    "    demand_amount : float\n",
    "        Demand amount for the given sector.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Final demand vector with a given demand amount for a given sector and 0 for all other sectors.\n",
    "    \"\"\"\n",
    "    f_vector = np.zeros(number_of_sectors)\n",
    "    f_vector[sector_index] = demand_amount\n",
    "    return f_vector\n",
    " \n",
    "\n",
    "def compute_environmental_burden(\n",
    "    A_H: np.ndarray,\n",
    "    B_H: np.ndarray,\n",
    "    Q_H_climate: np.ndarray,\n",
    "    sector_index: int,\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Computes the environmental burden for a given sector index.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    - [Eqn. (2.35) and (8.27) in Heijungs & Suh (2002)](https://doi.org/10.1007/978-94-015-9900-9)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_H : np.ndarray\n",
    "        Hybrid A-matrix.\n",
    "    B_H : np.ndarray\n",
    "        Hybrid biosphere/environmental satellite matrix.\n",
    "    Q_H_climate : np.ndarray\n",
    "        Hybrid characterization matrix.\n",
    "    sector_index : int\n",
    "        Index of the sector for which the environmental burden should be computed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[float, float]\n",
    "        Tuple with the environmental burden and the computation time.\n",
    "    \"\"\"\n",
    "    f_vector_H = generate_final_demand_vector(\n",
    "        number_of_sectors=A_H.shape[0],\n",
    "        sector_index=sector_index,\n",
    "        demand_amount=1\n",
    "    )\n",
    "    start = time.time()\n",
    "    vec_intermediate_demand = np.linalg.solve(A_H, f_vector_H)\n",
    "    vec_environmental_flows = np.dot(B_H, vec_intermediate_demand)\n",
    "    scalar_environmental_burden = np.dot(Q_H_climate, vec_environmental_flows)\n",
    "    end = time.time()\n",
    "    computation_time = end - start\n",
    "    return scalar_environmental_burden, computation_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting calculations, ensure that your local NumPy is built against a fast [BLAS library](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms) (e.g., Intel MKL, OpenBLAS, or Apple Accelerate). Note that on a 2021 MacBook Pro (M1 Max CPU) with NumPy v2.2.1 [built against Apple Accelerate](https://numpy.org/doc/2.0/release/1.21.0-notes.html#enable-accelerate-framework), one computation takes approximately 130-190 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_computation(\n",
    "    dict_sample_process_indices: dict,\n",
    "    number_of_iterations: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Computes the environmental burden and computation time for a given sector index.\n",
    "    For every sector, the computation is repeated a given number of times to check for numerical stability.\n",
    "\n",
    "    For every ISIC letter (=section), the function stores the results in a pandas DataFrame and saves it as a pickle file.\n",
    "\n",
    "    The DataFrame is of the form:\n",
    "\n",
    "    | sector_index | computation_times | environmental_burden | cv  |\n",
    "    |--------------|-------------------|----------------------|-----|\n",
    "    | 1452         | [150, 155, 148]   | [0.1, 0.1, 0.1]      | 0.0 |\n",
    "    | 2254         | [156, 171, 180]   | [0.3, 0.3, 0.3]      | 0.0 |\n",
    "    | ...          | ...               | ...                  | ... |\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dict_sample_process_indices : dict\n",
    "        Dictionary with ISIC letters as keys and lists of sampled process indices as values.\n",
    "        For example: {'A': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'B': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19], ...}\n",
    "    \"\"\"\n",
    "    for isic_letter in dict_sample_process_indices.keys():\n",
    "        print('Now processing ISIC section:', isic_letter)\n",
    "        list_of_list_computation_times = []\n",
    "        list_of_list_results = []\n",
    "        list_cv = []\n",
    "        for sector_index in dict_sample_process_indices[isic_letter]:\n",
    "            list_results = []\n",
    "            list_computation_times = []\n",
    "            print('Index of sector:', sector_index)\n",
    "            for _ in range(0, number_of_iterations):\n",
    "                result = compute_environmental_burden(\n",
    "                    A_H=A_H,\n",
    "                    B_H=B_H,\n",
    "                    Q_H_climate=Q_H_climate,\n",
    "                    sector_index=sector_index\n",
    "                )\n",
    "                list_results.append(result[0])\n",
    "                print(f'Computing environmental burden took {result[1]} seconds.')\n",
    "                list_computation_times.append(result[1])\n",
    "            \n",
    "            std_result = np.std(list_results, ddof=1)\n",
    "            mean_result = np.mean(list_results)\n",
    "            list_cv.append(std_result / mean_result)\n",
    "            list_of_list_results.append(list_results)\n",
    "            list_of_list_computation_times.append(list_computation_times)\n",
    "\n",
    "        df_results_isic_section = pd.DataFrame(\n",
    "            {\n",
    "                'sector_index': dict_sample_process_indices[isic_letter],\n",
    "                'computation_times': list_of_list_computation_times,\n",
    "                'environmental_burden': list_of_list_results,\n",
    "                'cv': list_cv\n",
    "            }\n",
    "        )\n",
    "        with open(f'results_section_{isic_letter}.pkl', 'wb') as f:\n",
    "            pickle.dump(df_results_isic_section, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_computation(\n",
    "    dict_sample_process_indices=dict_sample_process_indices,\n",
    "    number_of_iterations=5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
